=========================================================================================================================================================
														部署安装程序及第三方软件安装配置
=========================================================================================================================================================

=========================================================================================================================================================
目录
	1、nacos及集群配置
	2、skywalking
	3、服务组件（应用程序）
	4、前端vue部署
	5、安装minio对象存储及集群配置
	6、JDK安装
	7、JDK证书支持
	8、安装redis及主从配置、哨兵配置
	9、安装mysql及主从配置
	10、安装fdfs及集群配置
	11、nginx安装
	12、logstash安装配置
	13、kibana安装配置
	14、websocket-demo页面发布
	15、安装screen
	16、安装nc
	17、安装erlang
	18、安装rabbitMQ

=========================================================================================================================================================

1、nacos
	-- nacos-server-2.0.2.zip（已升级到2.1.0）
		-- 修改配置文件
			-- application.properties
				-- spring.datasource.platform=mysql
				-- db.num=1
				-- db.url.0=jdbc:mysql://192.168.33.43:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC
				-- db.user.0=root
				-- db.password.0=1234
		-- 创建数据库
			-- 源码中脚本
				-- \oner365-cloud\scripts\*
		-- 启动nacos
			-- ./startup.sh -m standalone
		-- 访问地址
			-- http://xxx.xxx.x.xxx:8488/nacos
				-- http://192.168.33.44:8488/nacos
					-- nacos
					-- nacos
		-- jdk11不兼容修改
			-- vi startup.sh
				-- 找到注释
					-- #JAVA_OPT_EXT_FIX="-Djava.ext.dirs=${JAVA_HOME}/jre/lib/ext:${JAVA_HOME}/lib/ext"
				-- 修改成
  					-- JAVA_OPT="${JAVA_OPT} -Djava.ext.dirs=${JAVA_HOME}/jre/lib/ext:${JAVA_HOME}/lib/ext"
  				-- 找到注释
  					-- #echo "$JAVA $JAVA_OPT_EXT_FIX ${JAVA_OPT}"
  				-- 修改成
					-- echo "$JAVA ${JAVA_OPT}"
				-- 找到注释
					-- #echo "$JAVA $JAVA_OPT_EXT_FIX ${JAVA_OPT}" > ${BASE_DIR}/logs/start.out 2>&1 &
				-- 修改成
					-- echo "$JAVA ${JAVA_OPT}" > ${BASE_DIR}/logs/start.out 2>&1 &
				-- 找到注释
					-- #nohup "$JAVA" "$JAVA_OPT_EXT_FIX" ${JAVA_OPT} nacos.nacos >> ${BASE_DIR}/logs/start.out 2>&1 &
				-- 修改成
					-- nohup "$JAVA" ${JAVA_OPT} nacos.nacos >> ${BASE_DIR}/logs/start.out 2>&1 &
		-- 集群配置（建议3台或3台以上集群）
			-- 修改cluster.conf
				-- 增加集群配置
					--  192.168.33.41:8848
						192.168.33.42:8848
						192.168.33.43:8848
			-- 将配置好的nacos复制到不同服务器
				-- scp命令即可
			-- 将集群服务器的nacos启动
				-- ./nacos/bin/startup.sh
			-- 查看是否配置成功
				-- 进入任意一台nacos，查看“集群管理”
			-- 服务注册
				-- 两种模式
					-- slb负载代理
						-- 是用nginx及haproxy代理集群nacos
							-- 详见
								-- nacos集群代理安装配置文档
						-- 可试用nginx或F5等负载工具代理负载对应nacos地址
						-- bootstrap注册地址只写slb地址及端口号即可
					-- bootstrap注册地址写多个
						-- cloud:
						     nacos:
						       server-addr: 192.168.33.41:8848,192.168.33.42:8848,192.168.33.43:8848

2、skywalking
	-- apache-skywalking-apm-es7-8.6.0.tar.gz
		-- 解压
			-- tar -zxvf apache-skywalking-apm-es7-8.6.0.tar.gz
		-- 修改配置文件
			-- application.yml
				-- 注册中心修改
					-- cluster:
						 selector: ${SW_CLUSTER:nacos}
						 nacos:
						    serviceName: ${SW_SERVICE_NAME:"SkyWalking_OAP_Cluster"}
						    hostPort: ${SW_CLUSTER_NACOS_HOST_PORT:192.168.33.43:8848}
						    # Nacos Configuration namespace
						    namespace: ${SW_CLUSTER_NACOS_NAMESPACE:"public"}
						    # Nacos auth username
						    username: ${SW_CLUSTER_NACOS_USERNAME:"nacos"}
						    password: ${SW_CLUSTER_NACOS_PASSWORD:"nacos"}
						    # Nacos auth accessKey
						    accessKey: ${SW_CLUSTER_NACOS_ACCESSKEY:""}
						    secretKey: ${SW_CLUSTER_NACOS_SECRETKEY:""}
				-- 数据库连接、es配置修改
					-- storage:
						  selector: ${SW_STORAGE:mysql}
						  elasticsearch:
						    nameSpace: ${SW_NAMESPACE:""}
						    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:192.168.33.42:9200}
						    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:"http"}
						    user: ${SW_ES_USER:""}
						    password: ${SW_ES_PASSWORD:""}
						    trustStorePath: ${SW_STORAGE_ES_SSL_JKS_PATH:""}
						    trustStorePass: ${SW_STORAGE_ES_SSL_JKS_PASS:""}
						    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:""} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.
						    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.
						    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1} # Shard number of new indexes
						    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:1} # Replicas number of new indexes
						    # Super data set has been defined in the codes, such as trace segments.The following 3 config would be improve es performance when storage super size data in es.
						    superDatasetDayStep: ${SW_SUPERDATASET_STORAGE_DAY_STEP:-1} # Represent the number of days in the super size dataset record index, the default value is the same as dayStep when the value is less than 0
						    superDatasetIndexShardsFactor: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5} #  This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces.
						    superDatasetIndexReplicasNumber: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_REPLICAS_NUMBER:0} # Represent the replicas number in the super size dataset record index, the default value is 0.
						    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the async bulk record data every ${SW_STORAGE_ES_BULK_ACTIONS} requests
						    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests
						    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests
						    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}
						    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}
						    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}
						    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}
						    oapAnalyzer: ${SW_STORAGE_ES_OAP_ANALYZER:"{\"analyzer\":{\"oap_analyzer\":{\"type\":\"stop\"}}}"} # the oap analyzer.
						    oapLogAnalyzer: ${SW_STORAGE_ES_OAP_LOG_ANALYZER:"{\"analyzer\":{\"oap_log_analyzer\":{\"type\":\"standard\"}}}"} # the oap log analyzer. It could be customized by the ES analyzer configuration to support more language log formats, such as Chinese log, Japanese log and etc.
						    advanced: ${SW_STORAGE_ES_ADVANCED:""}
						  elasticsearch7:
						    nameSpace: ${SW_NAMESPACE:""}
						    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:192.168.33.42:9200}
						    protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:"http"}
						    trustStorePath: ${SW_STORAGE_ES_SSL_JKS_PATH:""}
						    trustStorePass: ${SW_STORAGE_ES_SSL_JKS_PASS:""}
						    dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index.
						    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1} # Shard number of new indexes
						    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:1} # Replicas number of new indexes
						    # Super data set has been defined in the codes, such as trace segments.The following 3 config would be improve es performance when storage super size data in es.
						    superDatasetDayStep: ${SW_SUPERDATASET_STORAGE_DAY_STEP:-1} # Represent the number of days in the super size dataset record index, the default value is the same as dayStep when the value is less than 0
						    superDatasetIndexShardsFactor: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5} #  This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces.
						    superDatasetIndexReplicasNumber: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_REPLICAS_NUMBER:0} # Represent the replicas number in the super size dataset record index, the default value is 0.
						    user: ${SW_ES_USER:""}
						    password: ${SW_ES_PASSWORD:""}
						    secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:""} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool.
						    bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the async bulk record data every ${SW_STORAGE_ES_BULK_ACTIONS} requests
						    flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests
						    concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests
						    resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}
						    metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}
						    segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}
						    profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200}
						    oapAnalyzer: ${SW_STORAGE_ES_OAP_ANALYZER:"{\"analyzer\":{\"oap_analyzer\":{\"type\":\"stop\"}}}"} # the oap analyzer.
						    oapLogAnalyzer: ${SW_STORAGE_ES_OAP_LOG_ANALYZER:"{\"analyzer\":{\"oap_log_analyzer\":{\"type\":\"standard\"}}}"} # the oap log analyzer. It could be customized by the ES analyzer configuration to support more language log formats, such as Chinese log, Japanese log and etc.
						    advanced: ${SW_STORAGE_ES_ADVANCED:""}
					    mysql:
						    properties:
						      jdbcUrl: ${SW_JDBC_URL:"jdbc:mysql://192.168.33.43:3306/swtest"}
						      dataSource.user: ${SW_DATA_SOURCE_USER:root}
						      dataSource.password: ${SW_DATA_SOURCE_PASSWORD:1234}
						      dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true}
						      dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250}
						      dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048}
						      dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true}
						    metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}
						    maxSizeOfArrayColumn: ${SW_STORAGE_MAX_SIZE_OF_ARRAY_COLUMN:20}
						    numOfSearchableValuesPerTag: ${SW_STORAGE_NUM_OF_SEARCHABLE_VALUES_PER_TAG:2}
				-- 启动
					-- ./apache-skywalking-apm-bin-es7/bin/.startup.sh
				-- 访问地址
					-- http://192.168.33.44:8080
3、服务组件
	-- 服务组件打包、部署目录结构
		-- 组件根目录（oner365）
			-- lib（依赖包）
			-- agent（skywalking）
			-- 服务组件（oner365-getway、oner365-system等）
				-- xxx.jar（oner365-gateway-1.0.0-SNAPSHOT.jar）
				-- start.sh
				-- tpid（启动进程号，启动生成）
				-- resources
					-- bootstrap.yml（启动配置）
					-- logback-spring.xml（日志配置）
			-- logs（所有服务默认日志目录）
		-- 程序服务打包
			-- 打包程序jar
				-- maven命令
					-- mvn clean install
				-- eclipse
					-- Run As
						-- maven install
			-- 打包发布程序包
				-- 配置
					-- oner365-deploy
						-- src
							-- main
								-- resources
									-- application.yml
										-- 配置
											-- 源码地址
											-- 生成包地址
											-- 需要打包的服务名称
				-- 打包
					-- com.oner365.deploy.test.DeployTest.java
			

	-- 例（所有服务部署步骤相同）
		-- getway
			-- 添加、修改配置文件
				-- 地址
					-- http://192.168.33.44:8848/nacos
						-- 配置管理
							-- 配置列表
								-- 对应服务的配置文件
									-- 各种连接地址配置等
			-- 上传程序包（“程序服务打包”步骤中打成的部署包）
			-- 启动服务
				-- window系统生成start.sh可能出现换行错误（\n\r）
					-- 去掉\r命令
						-- sed -i 's/\r$//' start.sh 
				-- ./start.sh

4、前端vue部署
	-- 安装及配置nginx
		-- 查看《第三方软件安装说明》.docx
		
	-- vue部署
		-- 上传程序
			-- /home/oner365/oner365-vue
		-- 启动nginx
		-- 访问地址
			--  http://192.168.33.44

5、minio
	-- 单机
		-- 安装
			-- cd /安装目录
			-- wget https://dl.minio.io/server/minio/release/linux-amd64/minio
		-- 启动停止shell
			-- minio/单机/start.sh
			-- minio/单机/stop.sh
			-- 修改shell中minio安装目录
	-- 集群
		-- 特点
			-- 数据保护
				-- 分布式Minio采用纠删码来防范多个节点宕机和位衰减 bit rot
				-- 分布式Minio至少需要4个硬盘，使用分布式Minio自动引入了纠删码功能
			-- 高可用
				-- 分布式Minio,只要有N/2硬盘在线，数据就是安全的
			-- 一致性
				-- Minio在分布式和单机模式下，所有读写操作都严格遵守read-after-write一致性模型
		-- 分布式部署主要以修改启动配置来实现
		-- 安装
			-- 4台服务器（可磁盘分布式），可节点分布式（多节点，多磁盘））（至少4个磁盘点，服务器节点可对应扩展）
				-- 1节点4磁盘（四个不同磁盘服务器，可使用同服务器不同磁盘地址）
					-- shell 启动文件修改
						-- minio server --address 0.0.0.0:9001 --console-address 0.0.0.0:9003  --config-dir /home/minio \ http://192.168.33.41:9001/home/minio/data \ http://192.168.33.42:9001/home/minio/data \ http://192.168.33.43:9001/home/minio/data \ http://192.168.33.44:9001/home/minio/data > minio.log 2>&1 &
				-- 4节点16磁盘
					-- 每台服务器安装minio
						-- 同单机
					-- shell 启动文件修改
						-- minio/集群/start.sh
						-- minio/集群/stop.sh
						-- 修改shell中minio安装目录
					-- 启动
						-- 启动minio时日志会报错，只要ps进程在就ok，报错是在等其他节点
					-- 验证
						-- 四个节点都起来后,可访问任意节点ip的9003管理后台
						-- 在节点上创建桶和上传文件
						-- 在其他节点也可看到创建的桶和文件，可操作
				-- nginx负载
					-- 安装一台负载用nginx
					-- 配置conf
						-- minio/集群/nginx_minio.conf
							-- 此conf使用了其中一台节点的服务器，所以端口修改为9002，9004.
					-- 通过nginx配置端口访问minio管理后台，可创建可上传即可

6、jdk安装
	-- cd /opt
	-- rpm -ivh jdk-8u202-linux-x64.rpm
	-- vi /etc/profile
		-- export JAVA_HOME=/usr/java/default
		   export PATH=$JAVA_HOME/bin:$PATH
		   export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
	-- source /etc/profile

7、jdk证书支持
	-- CFCA证书jdk暂时不支持
		-- 执行命令导入相关需要访问的CFCA颁发的证书的网站
			-- sudo keytool -import -v -trustcacerts -alias 别名 -keystore "${JAVA_HOME}(jdk11没有jre目录)/jre/lib/security/cacerts" -file /证书路径/server.cer -storepass 
			-- 删除导入证书
				-- sudo keytool -delete -alias 别名 -keystore ${JAVA_HOME}(jdk11没有jre目录)/jre/lib/security/cacerts
			-- 查看导入证书（jdk 默认密码 changeit）
				-- sudo keytool -list -keystore ${JAVA_HOME}(jdk11没有jre目录)/jre/lib/security/cacerts -v |grep 别名
				-- sudo keytool -list -keystore ${JAVA_HOME}(jdk11没有jre目录)/jre/lib/security/cacerts -v -alias 别名


8、安装redis
	-- cd /opt
	-- tar -zxvf redis-6.0.5.tar.gz
	-- cd redis-6.0.5/
	-- make && make install
	-- make install PREFIX=/usr/local/redis
	-- 修改redis.conf
		-- vi /opt/redis-6.0.5/redis.conf
			-- daemonize yes
			-- bind 0.0.0.0
			-- requirepass 1qazXSW@
			-- 主从配置
				-- masterauth 1qazXSW@
				-- slave-read-only yes
				-- slaveof xxx.xxx.xxx.xxx 6379

	-- 启动
		-- cd /usr/local/redis/bin
		-- ./redis-server /opt/redis-5.0.3/redis.conf
	-- redis 哨兵
		-- 修改配置文件
			-- redis.conf （主，master）
				-- appendonly yes
				-- protected-mode no
				-- requirepass "1qazXSW@"
				-- masterauth "1qazXSW@"
				-- daemonize yes
			-- redis.conf (从机 slave)
				-- slaveof 192.168.33.43 6379
				-- appendonly yes
				-- protected-mode no
				-- requirepass "1qazXSW@"
				-- masterauth "1qazXSW"
			-- sentinel.conf(主 master，从 slave)
				-- protected-mode no
				-- daemonize yes
				-- sentinel monitor mymaster 192.168.33.43 6379 2
					-- 监听主机 名称mymaster 端口6379 投票2（两个监听投票即认为主机故障，有运维人员建议设置为哨兵数/2-1，就是3台哨兵就设置为1）
				-- sentinel auth-pass mymaster 1qazXSW@
					-- mymaster认证密码（同redis masterauth密码）
				-- sentinel down-after-milliseconds 10000
					-- 主机宕机后多少秒进行主从切换 默认30秒
			-- 依次启动
				-- 启动主redis
					--  ./redis-server /opt/redis-6.0.5/redis.conf
				-- 启动从redis（两台）
					-- ./redis-server /opt/redis-6.0.5/redis.conf
				-- 启动主sentinel监听
					-- ./redis-sentinel /opt/redis-6.0.5/sentinel.conf
				-- 启动从sentinel监听（两台）
					-- ./redis-sentinel /opt/redis-6.0.5/sentinel.conf
			-- 实例
				-- 192.168.33.43（master）
				-- 192.168.33.44（slave）
				-- 192.168.33.41（slave）
				-- shutdown master
				-- 进入slave机器cli
					-- ./redis-cli
						-- auth 1qazXSW@
						-- info replication 查看主从状态
9、mysql安装
	-- yum install libncurses*
	-- xz -d mysql-8.0.17-linux-glibc2.12-x86_64.tar.xz 
	-- cd /usr/local/
	-- tar -xvf /opt/mysql-8.0.17-linux-glibc2.12-x86_64.tar 
	-- mkdir -p /var/run/mysqld
	-- groupadd mysql
	-- useradd -r -g mysql mysql
	-- ln -s mysql-8.0.17-linux-glibc2.12-x86_64 mysql
	-- chmod 777 -R /var/run/mysqld/*
	-- chmod 777 -R /var/run/mysqld
	-- chown -R mysql /usr/local/mysql
	-- chown -R mysql /usr/local/mysql/*
	-- cd mysql
	-- chgrp -R mysql .
	-- mkdir /home/data
	-- mkdir /home/tmp
	-- chmod -R 777 /home/data /home/tmp
	-- chmod 777 -R /var/run/mysqld
	-- chmod 777 -R /var/log
	-- 修改my.conf
		-- vi /etc/my.cnf
			--      [mysqld]
				basedir=/usr/local/mysql
				datadir=/home/data
				socket=/home/tmp/mysql.sock
				symbolic-links=0

				log-error=/var/log/mysqld.log
				pid-file=/usr/local/mysql/mysqld.pid

				[client] 
				default-character-set=utf8 
				socket=/home/tmp/mysql.sock

				[mysql] 
				default-character-set=utf8 
				socket=/home/tmp/mysql.sock
	-- cd /usr/local/mysql
	-- chown -R mysql:mysql ./
	-- ./bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/home/data 
		-- 如报错
			-- ./bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory
			-- 执行
				-- yum install libaio
	-- cp support-files/mysql.server /etc/init.d/mysql
	-- chmod +x /etc/init.d/mysql
	-- chkconfig --add mysql
	-- 修改环境变量
		-- vi /etc/profile
			-- /usr/local/mysql/bin:PATH
		-- source /etc/profile
	-- 查看初始密码
		-- grep "password" /var/log/mysqld.log
	-- 启动
		-- service mysql start
	-- 连接数据库
		-- mysql -u root -p --default-character-set=utf8
		-- 密码是上面查出来的
		-- 修改密码授权，远程连接
			-- alter user 'root'@'localhost' identified by '1qazXSW@';
			-- flush privileges; 
			-- use mysql;
			-- update user set host = '%' where user ='root';
			-- flush privileges; 
			-- exit;
	-- 主从配置
		-- 新装数据库时直接配置即可，使用中数据库，提前手工同步下数据
		-- 修改my.cnf（主机）server-id主从机器不能一样
			-- vi /etc/my.cnf
				-- [mysqld]下
					-- log-bin=mysql-bin
					   server-id=1
		-- 修改my.cnf（从机）server-id主从机器不能一样
			-- vi /etc/my.cnf
				-- [mysqld]下
					-- server-id=2
		-- 创建同步用户（主机）
			-- create user 'repl'@'%' identified by 'repl123456';
			-- grant replication slave on *.* to 'repl'@'%';
			-- flush privileges;
		-- 查看主机binglog状态
			-- SHOW MASTER STATUS;
		-- 从机配置同步节点
			-- CHANGE MASTER TO
			   MASTER_HOST='10.5.48.14',
			   MASTER_USER='repl',
			   MASTER_PASSWORD='repl123456',
			   MASTER_LOG_FILE='binlog.000001',
			   MASTER_LOG_POS=60731;
			-- MASTER_LOG_FILE 主机 SHOW MASTER STATUS;命令中binlog日志文件名
			-- MASTER_LOG_POS 主机 SHOW MASTER STATUS;命令中MASTER_LOG_POS字段值
		-- 启动/停止同步
			-- START SLAVE;
			-- STOP SLAVE;
		-- 查看同步状态
			-- show slave status\G;
			-- show slave status; 第三方工具用这个上面那个不行（navicat）
			-- 同步成功/失败查看
				-- Slave_IO_Running: Yes
				-- Slave_SQL_Running: Yes 
				-- 两个值都是YES时成功，如失败查看
					-- Last_IO_Error字段提示
		-- 常见错误
			-- Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: 'Could not find first log file name in binary log index file'
				-- 此错误为MASTER_LOG_FILE文件名称未对应主机master
				-- 修改
					-- SHOW MASTER STATUS; 查看主机状态获取MASTER_LOG_FILE
					-- change master to master_log_file='主机MASTER_LOG_FILE',master_log_pos=主机MASTER_LOG_POS;
			-- Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it).
				-- 此错误为server-id使用相同
				-- 排查
					-- show variables like 'server_id';
						-- 得出结果如果与主机相同请确认my.cnf修改生效（与主机不同），重启从机mysql，stop，start不要restart，mysql的restart有时不生效
			-- Last_IO_Error: error connecting to master 'repl@10.5.48.14:3306' - retry-time: 60 retries: 4 message: Authentication plugin 'caching_sha2_password' reported error: Authentication requires secure connection.
				-- 此错误为主机创建用户认证不通过，mysql8认证方式不同
				-- 检查主机用户创建配置
				-- 检查主机用户连接
					-- select user,host from user;
				-- 是否刷新权限
					-- flush privileges;
10、fdfs安装
	-- cd /opt
	-- mkdir /home/fastdfs /home/fastdfs-storage
	-- cd /opt/fastdfs6.06/fastdfs-file
	-- unzip libfastcommon-1.44.zip
	-- cd libfastcommon-master/
	-- ./make.sh
	-- ./make.sh install
	-- ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so
	-- ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so 
	-- cd /opt/fastdfs6.06/fastdfs-file
	-- unzip fastdfs-6.06.zip 
	-- mv fastdfs-master fastdfs
	-- mv -f fastdfs /usr/local
	-- cd /usr/local/fastdfs
	-- ./make.sh 
	-- ./make.sh install
	-- cd /etc/fdfs/
	-- mv tracker.conf.sample tracker.conf
	-- vi tracker.conf
		-- base_path=/home/fastdfs
	-- ln -s /usr/bin/fdfs_trackerd /usr/local/bin
	-- ln -s /usr/bin/stop.sh /usr/local/bin
	-- ln -s /usr/bin/restart.sh /usr/local/bin
	-- service fdfs_trackerd start
	-- cd /etc/fdfs/
	-- mv storage.conf.sample storage.conf
	-- vi storage.conf
		-- base_path=/home/fastdfs-storage   
		-- store_path0=/home/fastdfs-storage  
		-- tracker_server=10.5.48.14:22122   
	-- ln -s /usr/bin/fdfs_storaged /usr/local/bin
	-- service fdfs_storaged start
	-- /usr/bin/fdfs_monitor /etc/fdfs/storage.conf
	-- fastdfs nginx模块安装
		-- cd /opt/fastdfs6.06/fastdfs-file/
		-- unzip fastdfs-nginx-module-1.22.zip
		-- cd fastdfs-nginx-module-master/src/
		-- vi config 
		-- ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so
		-- ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so
		-- cp /opt/fastdfs-conf/fastdfs-conf/fdfs/mod_fastdfs.conf /etc/fdfs
		-- cp /usr/local/fastdfs/conf/mime.types /etc/fdfs
		-- cp /usr/local/fastdfs/conf/http.conf /etc/fdfs
		-- cp /usr/local/fastdfs/conf/anti-steal.jpg /etc/fdfs
		-- vi /etc/fdfs/mod_fastdfs.conf 
			-- tracker_server=192.168.100.190:22122
			-- store_path0=/home/fastdfs
		-- cd /opt/fastdfs6.06/fastdfs-file/
		-- tar -xvf pcre-8.42.tar
		-- 此版本对centOS7.8编译有错，没解决可用
			-- nginx-1.19.1.tar.gz
			-- 其他步骤相同
		-- tar -zxvf nginx-1.19.1.tar.gz
		-- yum -y install gcc-c++
		-- cd nginx-1.19.1/
		-- ./configure --prefix=/usr/share/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/opt/fastdfs6.06/fastdfs-file/pcre-8.42 --add-module=/opt/fastdfs6.06/fastdfs-file/fastdfs-nginx-module-master/src
		-- make
		-- make install
		-- cd /usr/share/
		-- cp -rf nginx nginx9999
		-- cp /opt/fastdfs-conf/fastdfs-conf/nginx9999/conf/nginx.conf /usr/share/nginx9999/conf/
		-- vi /usr/share/nginx9999/conf/nginx.conf
			-- 修改root的storage地址
		-- cp /opt/fastdfs-conf/fastdfs-conf/fdfs/mod_fastdfs.conf /etc/fdfs/
		-- vi /etc/fdfs/mod_fastdfs.conf
			-- 修改
				-- base_path=/home/fastdfs-storage
				-- tracker_server=10.5.48.14:22122
				-- store_path0=/home/fastdfs-storage
				-- group
					-- 三个group的store_path0到指定目录
		-- cp /opt/fastdfs-conf/fastdfs-conf/fdfs/http.conf /etc/fdfs/
		-- vi /etc/fdfs/http.conf
			-- http.anti_steal.token_check_fail = /home/fastdfs/conf/anti-steal.jpg
		-- ln -s /home/fastdfs-storage/data /home/fastdfs-storage/data/M00
		-- cd /usr/share/nginx9999/sbin
		-- /usr/share/nginx9999/sbin/nginx -c /usr/share/nginx9999/conf/nginx.conf
		-- 此版本对centOS7.8编译有错，没解决可用
			-- nginx-1.19.1.tar.gz
			-- 其他步骤相同
		-- cd /opt/fastdfs6.06/fastdfs-file/nginx-1.19.1
		-- ./configure --prefix=/usr/share/nginx2 --with-http_stub_status_module --with-http_ssl_module --with-pcre=/opt/fastdfs6.06/fastdfs-file/pcre-8.42 --add-module=/opt/fastdfs6.06/fastdfs-file/fastdfs-nginx-module-master/src
		-- make
		-- make install
		-- cd /usr/share/nginx2/
		-- cp /opt/fastdfs-conf/fastdfs-conf/nginx2/conf/nginx.conf /usr/share/nginx2/conf/
		-- vi /usr/share/nginx2/conf/nginx.conf
			-- upstream fdfs_group1 ip地址
		-- ./sbin/nginx
		-- cp /opt/fastdfs-conf/fastdfs-conf/fdfs/client.conf /etc/fdfs/
		-- vi /etc/fdfs/client.conf
			-- base_path=/home/fastdfs-storage
			-- tracker_server=10.5.48.14:22122
		-- 图片上传测试
		-- /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /root/1.png 
		-- 集群配置
			-- vi /etc/fdfs/mod_fastdfs.conf
				-- tracker_server=10.5.48.14:22122 对应两台的tracker_server，有几个tracker写几个tracker_server
			-- vi /etc/fdfs/storage.conf 
				-- 增加
					-- tracker_server=10.5.48.13:22122 对应两台的tracker_server，有几个tracker写几个tracker_server
			-- service fdfs_storaged stop
			-- service fdfs_storaged start
			-- vi /etc/fdfs/client.conf
				-- 增加
					-- tracker_server=10.5.48.13:22122 对应两台的tracker_server，有几个tracker写几个tracker_server

11、安装nginx
	-- cd /opt
	-- tar -xvf pcre-8.42.tar
	-- tar -zxvf nginx-1.19.1.tar.gz
	-- yum -y install gcc-c++
	-- cd nginx-1.19.1/
	-- ./configure --prefix=/usr/share/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/opt/pcre-8.42 
	-- make
	-- make install
	-- 配置启动
12、安装logstash（8.x.x需要jdk11）
	-- cd /opt
	-- tar -zxvf logstash-8.1.0-darwin-x86_64.tar.gz
	-- vi logstash-8.1.0/config/logstash.yml
		--  node.name: logstash_uem
			pipeline.id: main
			pipeline.ordered: auto
			config.reload.automatic: true
			api.http.host: 127.0.0.1
			api.http.port: 9201
			queue.type: persisted
	-- 增加logstash.conf配置数据业务流程
		-- 查看
			-- logstash/logstash-sample.conf
				-- 此实例多端口监听
				-- 入库es多索引
				-- 时间格式转化
	-- 增加启动停止shell（logstash/start.sh,stop.sh）
		-- logstash-8.1.0/bin/
13、安装kibana(需要与es对应版本）
	-- cd /opt
	-- tar -zxvf kibana-7.6.2-linux-x86_64.tar.gz
	-- cd /opt/kibana-7.6.2-linux-x86_64
	-- vi config/kibana.yml
		--  server.port: 5601
			server.host: "0.0.0.0"
			elasticsearch.hosts: ["http://192.168.33.42:9200"]
			i18n.locale: "zh-CN"
	-- 增加启动停止shell（kibana/start.sh,stop.sh）
		-- kibana-7.6.2-linux-x86_64/bin/ 
	-- 访问地址
		-- http://192.168.33.44:5601
	-- 配置索引查看方式
		-- management --> kibana --> 索引模式 --> 创建索引模式 --> 选择要创建的索引，下一步，完成
	-- 查看索引模式（索引数据查询）
		-- Discover
			-- 可选择时间，key
14、websocket-demo页面发布
	-- demo页面文件目录
		-- websocket-demo/im-html 
	-- 将目录放到服务器任意有权限位置
	-- 修改nginx配置
		-- 部署文档/nginx_websocket.conf
			-- 指定文件存放地址
	-- 启动此文件
		-- /usr/share/nginx/sbin/nginx -c /usr/share/nginx/conf/nginx_websocket.conf
	-- 默认访问地址
		-- http://xxx.xxx.xxx.xxx:8799
15、安装screen
	-- yum install screen
	-- 主要命令
		-- 新开session
			-- screen -S session name
		-- 挂起
			-- ctrl+A D
		-- 退出
			-- exit
		-- session列表
			-- screen -ls
16、安装nc
	-- yum install nc
	-- 主要命令（查看执行机器公网出口ip）
		-- nc ns1.dnspod.net 6666
17、安装erlang
	-- tar /opt/tar -zxvf otp_src_22.0.tar.gz 
	-- yum install libtool libtool-ltdl-devel libevent-devel lua  ncurses-devel openssl-devel flex
	-- cd otp_src_22.0
	-- ./configure --prefix=/usr/local/erlang
	-- make && make install
	-- vi /etc/profile
		-- export ERLANG_HOME=/usr/local/erlang
		   export PATH=$ERLANG_HOME/bin:$PATH
	-- source /etc/profile
	-- 执行试试能不能进
		-- erl 
		-- 退出
			-- halt().
		-- erl -version
18、安装rabbitMQ	
	-- tar -xvf /opt/rabbitmq-server-generic-unix-3.7.25.tar 	
	-- mv -f rabbitmq_server-3.7.25 /usr/local/rabbitmq-server
	-- cd /usr/local/rabbitmq-server/sbin/
	-- ./rabbitmq-plugins enable rabbitmq_management
	-- ./rabbitmq-server -detached
	-- ./rabbitmqctl add_user admin admin123
	-- ./rabbitmqctl set_user_tags admin administrator






